{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0848e3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "gdp_data = pd.read_csv('GDP.csv')\n",
    "cpi_data = pd.read_csv('CPIAUCSL.csv')\n",
    "unemployment_data = pd.read_csv('Unemployment.csv')\n",
    "bond_yields_data = pd.read_csv('MarketY.csv')\n",
    "ys= pd.read_csv('T10Y2Y.csv')\n",
    "indexc=pd.read_csv('indexc.csv')\n",
    "ukexc=pd.read_csv('ukexc.csv')\n",
    "russexc=pd.read_csv('rubel_exc.csv')\n",
    "ir=pd.read_csv('MORTGAGE30US.csv')\n",
    "daaa=pd.read_csv('DAAA.csv')\n",
    "dbaa=pd.read_csv('DBAA.csv')\n",
    "dff_data = pd.read_csv('DFF.csv')\n",
    "umcsent_data = pd.read_csv('UMCSENT.csv')\n",
    "dgs30_data = pd.read_csv('DGS30.csv')\n",
    "dgs10_data = pd.read_csv('DGS10.csv')\n",
    "dgs3mo_data = pd.read_csv('DGS3MO.csv')\n",
    "dgs2_data = pd.read_csv('DGS2.csv')\n",
    "inflation=pd.read_csv('Inflation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a2a602",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gdp_data['observation_date'] = pd.to_datetime(gdp_data['observation_date'])\n",
    "cpi_data['observation_date'] = pd.to_datetime(cpi_data['observation_date'])\n",
    "unemployment_data['observation_date'] = pd.to_datetime(unemployment_data['observation_date'])\n",
    "bond_yields_data['observation_date'] = pd.to_datetime(bond_yields_data['observation_date'])\n",
    "ys['observation_date'] = pd.to_datetime(ys['observation_date'])\n",
    "indexc['observation_date'] = pd.to_datetime(indexc['observation_date'])\n",
    "ukexc['observation_date'] = pd.to_datetime(ukexc['observation_date'])\n",
    "russexc['observation_date'] = pd.to_datetime(russexc['observation_date'])\n",
    "ir['observation_date'] = pd.to_datetime(ir['observation_date'])\n",
    "daaa['observation_date'] = pd.to_datetime(daaa['observation_date'])\n",
    "dbaa['observation_date'] = pd.to_datetime(dbaa['observation_date'])\n",
    "dff_data['observation_date'] = pd.to_datetime(dff_data['observation_date'])\n",
    "umcsent_data['observation_date'] = pd.to_datetime(umcsent_data['observation_date'])\n",
    "dgs30_data['observation_date'] = pd.to_datetime(dgs30_data['observation_date'])\n",
    "dgs10_data['observation_date'] = pd.to_datetime(dgs10_data['observation_date'])\n",
    "dgs3mo_data['observation_date'] = pd.to_datetime(dgs3mo_data['observation_date'])\n",
    "dgs2_data['observation_date'] = pd.to_datetime(dgs2_data['observation_date'])\n",
    "inflation['observation_date'] = pd.to_datetime(inflation['observation_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5747b9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_data.set_index('observation_date', inplace=True)\n",
    "com=pd.date_range(start='1990-1-1', end='2024-11-01', freq='MS')\n",
    "gdp_data=gdp_data.reindex(com)\n",
    "gdp_data['GDP']=gdp_data['GDP'].interpolate(method='linear')\n",
    "gdp_data.reset_index(inplace=True)\n",
    "gdp_data.rename(columns={'index':'observation_date'}, inplace=True)\n",
    "gdp_data.columns=['observation_date', 'GDP']\n",
    "print(gdp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358e583a",
   "metadata": {},
   "outputs": [],
   "source": [
    "russexc.set_index('observation_date', inplace=True)\n",
    "com = pd.date_range(start='1990-1-1', end='2024-11-01', freq='MS')\n",
    "russexc = russexc.reindex(com)\n",
    "russexc['CCUSMA02RUM618N'] = russexc['CCUSMA02RUM618N'].interpolate(method='linear', limit_direction='both')\n",
    "russexc.reset_index(inplace=True)\n",
    "russexc.rename(columns={'index': 'observation_date'}, inplace=True)\n",
    "russexc.columns = ['observation_date', 'CCUSMA02RUM618N']\n",
    "russexc.to_csv('russexc_interpolated_extrapolated.csv', index=False)\n",
    "print(russexc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9a94a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all DataFrames have consistent column headers\n",
    "gdp_data.columns = ['observation_date', 'GDP']\n",
    "cpi_data.columns = ['observation_date', 'CPI']\n",
    "unemployment_data.columns = ['observation_date', 'unemployment']\n",
    "ys.columns = ['observation_date', 'Yield Spread']\n",
    "indexc.columns = ['observation_date', 'IND US']\n",
    "ukexc.columns = ['observation_date', 'US UK']\n",
    "russexc.columns = ['observation_date', 'US RUSSIA']\n",
    "ir.columns = ['observation_date', 'Interest Rate']\n",
    "daaa.columns = ['observation_date', 'DAAA']\n",
    "dbaa.columns = ['observation_date', 'DBAA']\n",
    "dff_data.columns = ['observation_date', 'DFF']\n",
    "umcsent_data.columns = ['observation_date', 'Sentiment']\n",
    "dgs30_data.columns = ['observation_date', 'DGS30']\n",
    "dgs10_data.columns = ['observation_date', 'DGS10']\n",
    "dgs3mo_data.columns = ['observation_date', 'DGS3MO']\n",
    "dgs2_data.columns = ['observation_date', 'DGS2']\n",
    "inflation.columns = ['observation_date', 'Inflation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9eaa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge datasets on the 'Date' column\n",
    "datasets = [\n",
    "    (gdp_data, 'observation_date'),\n",
    "    (cpi_data, 'observation_date'),\n",
    "    (unemployment_data, 'observation_date'),\n",
    "    (ys, 'observation_date'),\n",
    "    (indexc, 'observation_date'),\n",
    "    (ukexc, 'observation_date'),\n",
    "    (russexc, 'observation_date'),\n",
    "    (ir, 'observation_date'),\n",
    "    (daaa, 'observation_date'),\n",
    "    (dbaa, 'observation_date'),\n",
    "    (dff_data, 'observation_date'),\n",
    "    (umcsent_data, 'observation_date'),\n",
    "    (inflation, 'observation_date'),\n",
    "    (dgs10_data, 'observation_date'),\n",
    "    (dgs3mo_data, 'observation_date'),\n",
    "    (dgs2_data, 'observation_date'),\n",
    "]\n",
    "combined_data, merge_column = datasets[0]\n",
    "for data, column in datasets[1:]:\n",
    "    combined_data = combined_data.merge(data, on=column, how='outer')\n",
    "print(\"Datasets have been merged and saved as 'combined_us_market_data.csv'.\", combined_data)\n",
    "\n",
    "start_date = combined_data['observation_date'].min()\n",
    "end_date = combined_data['observation_date'].max()\n",
    "daily_dates = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "\n",
    "combined_data.set_index('observation_date', inplace=True)\n",
    "daily_data = combined_data.reindex(daily_dates).interpolate(method='time')\n",
    "daily_data.reset_index(inplace=True)\n",
    "daily_data.rename(columns={'index': 'observation_date'}, inplace=True)\n",
    "daily_data.to_csv('us_market_data_daily.csv', index=False)\n",
    "print(\"Monthly data has been converted to daily data and saved as 'us_market_data_daily.csv'.\")\n",
    "print(combined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704e9685",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_data = pd.read_csv('us_market_data_daily.csv')\n",
    "daily_data['observation_date'] = pd.to_datetime(daily_data['observation_date'])\n",
    "daily_data['observation_date'] = pd.to_datetime(daily_data['observation_date'], errors='coerce')\n",
    "daily_data.dropna(subset=['observation_date'], inplace=True)\n",
    "hourly_index = pd.date_range(\n",
    "    start=daily_data['observation_date'].min(), \n",
    "    end=daily_data['observation_date'].max(), \n",
    "    freq='H'\n",
    ")\n",
    "\n",
    "# Create a new DataFrame with the hourly index\n",
    "hourly_data = pd.DataFrame({'observation_date': hourly_index})\n",
    "\n",
    "# Merge the hourly DataFrame with the original daily DataFrame\n",
    "hourly_data = pd.merge_asof(\n",
    "    hourly_data.sort_values('observation_date'), \n",
    "    daily_data.sort_values('observation_date'), \n",
    "    on='observation_date'\n",
    ")\n",
    "# Function for Fourier Interpolation\n",
    "def fourier_interpolation(series, n_harmonics=5):\n",
    "    freq_components = np.fft.fft(series)\n",
    "    freq_components[n_harmonics:] = 0\n",
    "    return np.fft.ifft(freq_components).real\n",
    "numeric_columns = hourly_data.select_dtypes(include=['float64', 'int64']).columns\n",
    "for col in numeric_columns:\n",
    "    hourly_data[col] = fourier_interpolation(hourly_data[col])\n",
    "hourly_data.to_csv(r'us_market_data_hourly.csv', index=False)\n",
    "print(hourly_data.head(24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0aa3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.read_csv('us_market_data_hourly.csv')\n",
    "combined_data['observation_date'] = pd.to_datetime(combined_data['observation_date'])\n",
    "correlation_matrix = combined_data.drop(columns=['observation_date']).corr()\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566cc173",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['observation_date','unemployment', 'Yield Spread', 'US UK', 'Sentiment']\n",
    "filtered_data = combined_data.drop(columns=columns_to_drop)\n",
    "print(filtered_data.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
